<p align="center">
  <strong>Read this in other languages:</strong><br>
  <a href="../../TECHNICAL.md">English</a> ‚Ä¢ 
  <a href="./TECHNICAL.md">Espa√±ol</a>
</p>

> **Nota:** Esta traducci√≥n es mantenida por la comunidad y podr√≠a no estar completamente sincronizada con la [versi√≥n en ingl√©s](../../TECNICAL.md), que es la fuente can√≥nica de la documentaci√≥n.


# 1. Introducci√≥n y Filosof√≠a de Dise√±o

Este documento proporciona un an√°lisis t√©cnico profundo de la arquitectura interna de `axes`. A diferencia de la documentaci√≥n de usuario, su prop√≥sito es detallar las decisiones de dise√±o, patrones de software y estrategias de optimizaci√≥n que permiten a `axes` alcanzar sus objetivos de rendimiento y robustez.

## 1.1. El Problema T√©cnico Abordado

Los ejecutores de tareas tradicionales operan sobre un modelo sin estado y basado en texto. Este enfoque, aunque simple, introduce cuellos de botella fundamentales a medida que la complejidad del proyecto escala:

1. **Sobrecarga de Parseo en la Ruta Caliente:** Cada ejecuci√≥n requiere leer y parsear archivos de configuraci√≥n de texto (ej. `Makefile`, `Justfile`, `package.json`), una operaci√≥n intensiva en I/O y CPU que se repite innecesariamente.
2. **Gesti√≥n de Dependencias Impl√≠cita:** La relaci√≥n entre diferentes componentes de un monorepo (ej. `api` depende de `common-lib`) no est√° formalizada, lo que conduce a flujos de trabajo fr√°giles y a la falta de herencia de configuraci√≥n.
3. **Falta de Identidad Persistente:** La identificaci√≥n de un proyecto basada en su ruta en el sistema de archivos es inherentemente vol√°til. Operaciones como renombrar o mover un directorio rompen los flujos de trabajo y las referencias.

`axes` fue dise√±ado desde cero para resolver estos problemas a nivel arquitectural.

### 1.2. Los Tres Pilares de la Arquitectura `axes`

La arquitectura de `axes` se sustenta en tres principios fundamentales que trabajan en sinergia para ofrecer un rendimiento de √©lite y una robustez estructural.

#### 1.2.1. Estado Centralizado y Persistente (`GlobalIndex`)

El n√∫cleo de `axes` es un **√≠ndice global** (`GlobalIndex`), una base de datos binaria y compacta que act√∫a como la √∫nica fuente de verdad (`Single Source of Truth`) para todo el ecosistema de proyectos. Este √≠ndice mapea un **UUID inmutable** para cada proyecto a sus metadatos esenciales, como su ruta f√≠sica, su nombre y su relaci√≥n padre-hijo.

- **Rendimiento de Arranque:** Al utilizar un formato binario (`bincode`), la deserializaci√≥n del √≠ndice completo en memoria es √≥rdenes de magnitud m√°s r√°pida que el parseo de un equivalente en formato de texto (JSON, TOML). Esto minimiza dr√°sticamente la latencia de arranque en fr√≠o.
- **Robustez Estructural:** Al desacoplar la identidad l√≥gica (UUID) de la ubicaci√≥n f√≠sica (ruta), el sistema se vuelve resiliente a cambios en el sistema de archivos.

#### 1.2.2. Carga Perezosa y Concurrente (El Patr√≥n `Facade`)

`axes` opera bajo el principio de "trabajo m√≠nimo indispensable". La lectura y compilaci√≥n de los archivos `axes.toml` no ocurre al inicio. En su lugar, se construye una estructura ligera en memoria, la `ResolvedConfig`, que act√∫a como una **fachada** (`Facade Pattern`).

- **Resoluci√≥n Bajo Demanda:** Los datos de configuraci√≥n (scripts, variables, etc.) solo se cargan del disco y se combinan cuando un m√©todo como `get_script()` o `get_env()` es invocado por primera vez.
- **Concurrencia Optimizada:** El `ConfigLoader` utiliza un pool de hilos (`rayon`) para cargar y compilar las diferentes capas de la jerarqu√≠a de un proyecto de forma concurrente. La sincronizaci√≥n se gestiona eficientemente mediante promesas (`Arc<OnceLock<...>>`), asegurando que cada capa se compile una sola vez, incluso bajo demanda concurrente.

#### 1.2.3. Compilaci√≥n Anticipada (AOT) y Cach√© de AST

Este es el pilar m√°s cr√≠tico para el rendimiento en ejecuciones "calientes". `axes` no es un int√©rprete, es un compilador de flujos de trabajo con una cach√© persistente.

- **Compilaci√≥n a AST:** En la primera ejecuci√≥n ("ruta fr√≠a"), `axes` parsea los archivos `axes.toml` y compila los scripts y variables a una representaci√≥n intermedia optimizada: un **√Årbol de Sintaxis Abstracta (AST)**, materializado en nuestras `struct`s `Task`.
- **Cach√© Binaria por Capa:** Este AST, que ya es una estructura de datos nativa de Rust, se serializa a un archivo de cach√© binario (`.bin`). La clave de esta cach√© es un hash del contenido del archivo `axes.toml` original.
- **Ejecuciones Instant√°neas ("Ruta Caliente"):** En ejecuciones subsecuentes, si el hash del `axes.toml` no ha cambiado, `axes` omite por completo el parseo de texto. Carga directamente el AST pre-compilado desde la cach√© binaria, eliminando el principal cuello de botella de rendimiento.

### 1.3. Diagrama de Flujo: Ruta Fr√≠a vs. Ruta Caliente

El siguiente diagrama ilustra la diferencia fundamental en el flujo de trabajo entre la primera ejecuci√≥n de un script y las ejecuciones posteriores.

```mermaid
graph TD
    subgraph "Ciclo de Vida de la Configuraci√≥n en `axes`"
        
        A["<br><b>Inicio</b><br>Comando `axes` ejecutado"] --> B{"<br>¬øHash de <code>axes.toml</code> coincide<br>con el hash en <code>GlobalIndex</code>?"}

        B -- "<b>‚ùÑÔ∏è No (Ruta Fr√≠a / Cache Miss)</b>" --> C_IO["<br><b>[I/O Disco + CPU]</b><br>1. Leer <code>axes.toml</code>"]
        C_IO --> C_CPU["<br><b>[CPU Intensivo]</b><br>2. Parsear TOML y Compilar Scripts a AST (`Task`)"]
        C_CPU --> D_IO["<br><b>[I/O Disco]</b><br>3. Serializar y Escribir AST en Cach√© Binaria (<code>.bin</code>)"]
        D_IO --> E["<br><b>[En Memoria]</b><br>Usar el AST reci√©n compilado"]
        
        B -- "<b>üî• S√≠ (Ruta Caliente / Cache Hit)</b>" --> H_IO["<br><b>[I/O Disco M√≠nimo]</b><br>1. Leer Cach√© Binaria (<code>.bin</code>)"]
        H_IO --> H_CPU["<br><b>[CPU M√≠nimo]</b><br>2. Deserializar AST desde binario"]
        H_CPU --> E
        
        E --> F["[No depende de `axes`]<br><b>Ejecuci√≥n</b><br>El `TaskExecutor` opera sobre el AST en memoria"]
        F --> G["<br><b>Fin</b><br>"]

    end

    %% Nodos de bajo coste (operaciones en memoria, decisiones)
    style A fill:#e6f7ff,stroke:#0050b3,stroke-width:1px,color:#055
    style B fill:#e6f7ff,stroke:#0050b3,stroke-width:2px,color:#055
    style E fill:#e6f7ff,stroke:#0050b3,stroke-width:1px,color:#055
    style F fill:#808080,stroke:#0050b3,stroke-width:2px
    style G fill:#f0f0f0,stroke:#595959,stroke-width:1px,color:#055

    %% Nodos de la Ruta Caliente (I/O y CPU optimizados)
    style H_IO fill:#d9f7be,stroke:#237804,stroke-width:2px,color:#055
    style H_CPU fill:#d9f7be,stroke:#237804,stroke-width:1px,color:#055
    
    %% Nodos de la Ruta Fr√≠a (Coste alto)
    style C_IO fill:#fff1b8,stroke:#d48806,stroke-width:2px,color:#055
    style C_CPU fill:#ffd8bf,stroke:#d46b08,stroke-width:2px,color:#055
    style D_IO fill:#ffccc7,stroke:#cf1322,stroke-width:2px,color:#055
```

Esta arquitectura de compilaci√≥n y cacheo es lo que nos permite ofrecer la potencia de un orquestador con la velocidad de un simple ejecutor. Adem√°s, el uso de hashes para los nombres de archivo de cach√© permite que esta sea **compartida entre miembros de un equipo** a trav√©s de una unidad de red o un sistema de cach√© distribuido, asegurando que el coste de compilaci√≥n se pague **una sola vez para todo el equipo**.

## 2. Anatom√≠a de una Ejecuci√≥n: El Ciclo de Vida de un Comando

El proceso de ejecuci√≥n de un comando en `axes` est√° rigurosamente coreografiado para maximizar la velocidad, la seguridad y el consumo perezoso de recursos.

### 2.1. El Despachador Universal y la Gram√°tica

El binario `axes` recibe todos los argumentos en un vector (`Vec<String>`) y utiliza una gram√°tica universal (implementada en `bin/axes.rs`) para determinar la intenci√≥n del usuario. Esta l√≥gica tiene tres reglas de decisi√≥n primarias (Contexto, Acci√≥n, Argumentos) y es el punto donde se decide qu√© porci√≥n del input se interpretar√° como contexto (`<ctx>`) y cu√°l como comandos para el manejador (`[args...]`).

### 2.2. Resoluci√≥n de Contexto y Persistencia de Identidad (`core/context_resolver.rs`)

Antes de cargar cualquier configuraci√≥n, el sistema debe saber sobre qu√© proyecto se est√° operando.

1. **Prioridad de Resoluci√≥n:** El `context_resolver` transforma una entrada de texto (ej., `mi-app/api` o `g!`) en el **UUID** can√≥nico del proyecto. La resoluci√≥n sigue un estricto orden de prioridad: Alias (`g!`, `db!`), Navegaci√≥n Relativa (`.`, `..`, `*`, `**`), y finalmente Nombres de Proyecto (b√∫squeda jer√°rquica).
2. **Referencia Local (`ProjectRef`):** El sistema mantiene un archivo de referencia binario local (`project_ref.bin`) en cada directorio de proyecto (`.axes/`). Este archivo almacena el UUID del proyecto y el UUID de su padre. Si el √≠ndice global se corrompe, `axes` puede reconstruir la identidad del proyecto desde esta referencia local, asegurando la auto-reparaci√≥n del sistema.
3. **Optimizaci√≥n de `last_used`:** Cada resoluci√≥n exitosa de un contexto actualiza los *cache pointers* (`last_used`, `last_used_child`) en el `GlobalIndex` para acelerar futuras b√∫squedas (`**` y `*`).

### 2.3. Carga Concurrente de Capas (`core/config_loader.rs`)

Una vez que se conoce el UUID del proyecto objetivo, la `ResolvedConfig` (la fachada perezosa) inicia la fase de carga.

El `ConfigLoader` determina la jerarqu√≠a completa de herencia (desde el UUID objetivo hasta el proyecto ra√≠z `global`) y orquesta la carga de configuraci√≥n de estas capas de forma concurrente para minimizar la latencia.

#### Diagrama: Flujo de Carga de Capas

```mermaid
graph TD
    A["ResolvedConfig.get_env()"] --> B("ConfigLoader");
    B --> C("Identificar Jerarqu√≠a: [UUID_A, UUID_P, UUID_G]");

    C --> D_R(Rayon::scope);
    
    D_R --> E1("Tarea 1: load_layer_task(UUID_A)");
    D_R --> E2("Tarea 2: load_layer_task(UUID_P)");
    D_R --> E3("Tarea 3: load_layer_task(UUID_G)");

    E1 --> F1{"Cach√© Hit/Miss?"};
    E2 --> F2{"Cach√© Hit/Miss?"};
    E3 --> F3{"Cach√© Hit/Miss?"};

    F1 --> G_A("LayerPromise.set(Result<Arc<Task>>)");
    F2 --> G_P("LayerPromise.set(Result<Arc<Task>>)");
    F3 --> G_G("LayerPromise.set(Result<Arc<Task>>)");

    G_A --> H("ResolvedConfig.get_layer(UUID_A)");
    G_P --> H;
    G_G --> H;

    H --> I["Combinaci√≥n de Datos y Memorizaci√≥n"];
    I --> J["Resultado Final"];

    style D_R fill:#d9f7be,stroke:#237804,stroke-width:2px,color:#055
    style E1 fill:#fff1b8,stroke:#d48806,stroke-width:1px,color:#055
    style E2 fill:#fff1b8,stroke:#d48806,stroke-width:1px,color:#055
    style E3 fill:#fff1b8,stroke:#d48806,stroke-width:1px,color:#055

    %% Sincronizaci√≥n eficiente con Arc/OnceLock
    H -.-> G_A; 
    H -.-> G_P; 
    H -.-> G_G;
```

#### Mecanismos de Sincronizaci√≥n

1. **`LayerPromise` (`Arc<OnceLock<...>>`):** Cada tarea de carga de capa es as√≠ncrona. La `ResolvedConfig` obtiene una "promesa" para el resultado. El uso de `OnceLock` es crucial: si un hilo ya est√° calculando la cach√© de una capa, cualquier otro hilo que la necesite simplemente **bloquea y espera** el resultado en la misma `OnceLock`. Esto garantiza que la costosa operaci√≥n de *Cache Miss* (I/O + Compilaci√≥n) nunca se duplique, incluso en entornos altamente concurrentes.
2. **Gesti√≥n de `Cache Miss`:** Si se detecta un `Cache Miss` (el `axes.toml` ha cambiado), la tarea de carga procede a la compilaci√≥n y produce un `IndexUpdate`. Estos *updates* son recolectados por el hilo principal y aplicados al `GlobalIndex` en un orden secuencial (antes de que la aplicaci√≥n termine), garantizando la seguridad de la cach√©.

### 2.4. El Modelo de Comandos: Compilaci√≥n a `Task` (AST)

La compilaci√≥n es el paso donde el texto del usuario se transforma en una estructura de datos ejecutable optimizada.

1. **Desde TOML a AST:** `axes` convierte el flexible `ProjectConfig` (el formato de texto) en un `CachedProjectConfig`. Este proceso implica la transformaci√≥n de cada `Command` a un `Task`, que es nuestra representaci√≥n del AST. Un `Task` contiene una secuencia de `CommandExecution`s.
2. **Prop√≥sito de `Task`:** Almacenar scripts pre-parseados, tokens resueltos (`TemplateComponent`), y metadatos de ejecuci√≥n (`ignore_errors`, `run_in_parallel`). Esto elimina la necesidad de `shlex` y el parsing de plantillas en tiempo de ejecuci√≥n.
3. **Separaci√≥n de Modelos:** La cach√© binaria (`bincode`) solo almacena el `Task` compilado (y no el tipo intermedio `Command`), garantizando que la deserializaci√≥n sea segura, r√°pida y sin ambig√ºedades.

## 3. Estructuras de Datos Fundamentales y su Dise√±o

El rendimiento y la robustez de `axes` no son solo el resultado de algoritmos, sino tambi√©n del dise√±o deliberado de sus estructuras de datos. Cada `struct` ha sido dise√±ada para un prop√≥sito espec√≠fico dentro del ciclo de vida de la aplicaci√≥n.

### 3.1. La Dualidad del Estado: `GlobalIndex` vs. `ProjectRef`

`axes` gestiona el estado a dos niveles: uno global y uno local, creando un sistema resiliente y auto-reparable.

- **`GlobalIndex` (El Mapa Global):**
  - **Estructura:** Es un √∫nico archivo binario (`index.bin`) que contiene principalmente un `HashMap<Uuid, IndexEntry>`.
  - **Prop√≥sito:** Act√∫a como el √≠ndice primario para todas las operaciones de b√∫squeda y resoluci√≥n de contexto. Permite una resoluci√≥n de UUID a metadatos (ruta, nombre, padre) en tiempo constante O(1).
  - **Optimizaci√≥n de Alias:** Mantiene un `HashMap<String, Uuid>` separado para los alias. Esto es una decisi√≥n de dise√±o cr√≠tica: desacopla los "atajos" de la estructura jer√°rquica principal. Permite una resoluci√≥n de alias en O(1) sin necesidad de iterar sobre todos los proyectos, y habilita una relaci√≥n muchos-a-uno (m√∫ltiples alias pueden apuntar al mismo proyecto), una flexibilidad que se perder√≠a si el alias fuera una propiedad del `IndexEntry`.

- **`ProjectRef` (La Identidad Local):**
  - **Estructura:** Es un peque√±o archivo binario (`.axes/project_ref.bin`) dentro de cada proyecto.
  - **Prop√≥sito:** Act√∫a como una "etiqueta de identidad" inmutable para el proyecto. Almacena su propio `self_uuid`, `name`, y el `parent_uuid`.
  - **Robustez y Auto-Reparaci√≥n:** Este archivo es la clave de la resiliencia de `axes`. Si el `GlobalIndex` se corrompe o se elimina, el comando `axes register` puede recorrer el sistema de archivos y usar los `project_ref.bin` para **reconstruir el √≠ndice global** con total fidelidad. Permite que un proyecto sea movido o renombrado en el sistema de archivos y luego "re-registrado" sin perder su identidad hist√≥rica ni sus relaciones.

### 3.2. La Cadena de Transformaci√≥n de Comandos: De Texto a AST

Para lograr tanto flexibilidad para el usuario como rendimiento para el ejecutor, `axes` utiliza una cadena de transformaci√≥n de modelos de datos. Esta es la clave para la robustez de la serializaci√≥n que hemos logrado.

```mermaid
graph LR
    A("<b>1. Usuario</b><br><code>axes.toml</code>") --> B{"<b>2. Deserializador TOML</b><br>(<code>serde_toml</code>)"};
    
    subgraph "Fase de Carga y Compilaci√≥n (Cache Miss)"
        B --> C["<b>3. Modelo Flexible: <code>ProjectConfig</code></b><br>Usa <code>TomlCommand</code> y <code>TomlOpenWithConfig</code> con <code>#[serde(flatten)]</code> para m√°xima flexibilidad sint√°ctica."];
        C --> D["<b>4. Modelo Can√≥nico: <code>CanonicalCommand</code></b><br>Normaliza todas las variantes sint√°cticas (simple, secuencia, por plataforma) en una √∫nica struct estandarizada."];
        D --> E["<b>5. Modelo de Cach√© (AST): <code>CachedProjectConfig</code></b><br>Contiene <code>Task</code>s. Los <code>Command</code>s han sido compilados a esta representaci√≥n binaria y optimizada. Es 100% compatible con <code>bincode</code>."];
    end

    E --> F{"<b>6. Serializador Binario</b><br>(<code>bincode</code>)"};
    F --> G("<b>7. Cach√© en Disco</b><br><code>.bin</code>");

    subgraph "Fase de Ejecuci√≥n (Cache Hit)"
        G --> H{"<b>8. Deserializador Binario</b><br>(<code>bincode</code>)"};
        H --> I["<b>9. Modelo de Cach√© en Memoria: <code>CachedProjectConfig</code></b><br>El AST se carga directamente, sin parseo de texto."];
    end
    
    I --> J("<b>10. <code>TaskExecutor</code></b><br>Opera directamente sobre el AST.");

    style A fill:#f0f0f0,stroke:#333,color:#055
    style G fill:#f0f0f0,stroke:#333,color:#055
    style C fill:#e6f7ff,stroke:#096dd9,color:#055
    style D fill:#bae7ff,stroke:#096dd9,color:#055
    style E fill:#d9f7be,stroke:#237804,color:#055
    style I fill:#d9f7be,stroke:#237804,color:#055
```

- **`TomlCommand` y `TomlOpenWithConfig`:** Estas son structs de "solo-lectura" dise√±adas con la m√°xima flexibilidad para el usuario, usando atributos como `#[serde(untagged)]` y `#[serde(flatten)]`. Su √∫nico prop√≥sito es deserializar el `axes.toml` sin errores, aceptando m√∫ltiples formas de sintaxis.
- **`Command` y `CanonicalCommand`:** Act√∫an como una capa de normalizaci√≥n. Despu√©s del parseo inicial, todas las variantes de `TomlCommand` se convierten en una `CanonicalCommand`. Esto simplifica la l√≥gica de compilaci√≥n posterior, ya que solo tiene que tratar con una √∫nica estructura bien definida.
- **`Task`, `CommandExecution`, `TemplateComponent` (El AST):** Este es el producto final de la compilaci√≥n. Es una representaci√≥n en memoria, optimizada para la ejecuci√≥n, que descompone cada comando en sus componentes l√≥gicos (literales, par√°metros, sub-comandos din√°micos). Es esta estructura la que se serializa con `bincode` en la cach√©. Al ser una `struct` regular de Rust sin atributos "m√°gicos" de `serde`, su serializaci√≥n y deserializaci√≥n binaria es determinista, ultrarr√°pida y robusta.

### 3.3. El Analizador de Argumentos (`ArgResolver`)

El `ArgResolver` es el componente que une los par√°metros definidos en un `Task` con los argumentos proporcionados por el usuario en la l√≠nea de comandos.

- **Recopilaci√≥n y Validaci√≥n Previa:** Antes de la ejecuci√≥n, el sistema (`run::handle`, `start::handle`, etc.) atraviesa el `Task` aplanado y recopila **todas** las definiciones de par√°metros (`ParameterDef`) en una sola lista. Esta lista representa el "contrato" completo del script.
- **Resoluci√≥n en un Solo Paso:** El `ArgResolver` se construye una √∫nica vez con este contrato y los argumentos del usuario. En su constructor, realiza todas las validaciones:
  - Comprueba que todos los par√°metros `required` est√©n presentes.
  - Detecta conflictos, como el uso simult√°neo de un flag y su alias (`--verbose` y `-v`).
  - Detecta argumentos inesperados si el script no usa el token gen√©rico `<params>`.
- **Resultado Inmutable:** El `ArgResolver` produce un `HashMap` inmutable que mapea el token original (ej. `<params::0(required)>`) a su valor final resuelto. Durante la ejecuci√≥n, el `TaskExecutor` simplemente realiza b√∫squedas r√°pidas en este mapa, sin necesidad de parsear o validar nada m√°s.

### 3.4. El Sistema de Cach√©

- **Cach√© por Capa:** `axes` no tiene una √∫nica cach√© monol√≠tica, sino una cach√© por cada `axes.toml` en la jerarqu√≠a del proyecto. Esto mejora la granularidad y reduce la invalidaci√≥n: un cambio en `mi-app/api/axes.toml` solo invalida la cach√© de `api`, no la de `mi-app` ni la de `global`.
- **Gesti√≥n de la Cach√©:** El comando `axes <ctx> _cache clear` invalida la cach√© de una capa espec√≠fica eliminando su `config_hash` y `cache_dir` del `GlobalIndex`. La pr√≥xima vez que se necesite esa capa, se forzar√° una recompilaci√≥n. Un futuro comando `axes cache gc` se encargar√° de purgar del disco los archivos de cach√© binarios que ya no est√©n referenciados por ning√∫n proyecto en el `GlobalIndex`.

## 4. Optimizaciones Adicionales y Conclusiones de Rendimiento

M√°s all√° de los tres pilares arquitecturales, `axes` implementa una serie de optimizaciones a nivel de microarquitectura para minimizar la latencia en cada operaci√≥n.

### 4.1. El Patr√≥n de Memorizaci√≥n en `ResolvedConfig`

La fachada `ResolvedConfig` no solo es perezosa a nivel de I/O de disco, sino tambi√©n a nivel de computaci√≥n. Operaciones como la combinaci√≥n de variables de entorno de toda una jerarqu√≠a (`get_env()`) son costosas. Para evitar repetir este trabajo, `ResolvedConfig` utiliza un patr√≥n de **memorizaci√≥n interna**.

- **Mecanismo:** Cada m√©todo costoso (ej. `get_env`, `get_options`) utiliza un campo `memoized_*` protegido por un `Mutex`.
  - En la **primera llamada**, el `Mutex` se bloquea, se realiza el c√°lculo costoso (combinar `HashMap`s de todas las capas), y el resultado se almacena en el campo `memoized_*`.
  - En **todas las llamadas subsecuentes**, el `Mutex` se bloquea brevemente solo para comprobar que el resultado ya existe, y se devuelve instant√°neamente.
- **Optimizaci√≥n con `Arc`:** Para resultados que son colecciones grandes (como el `HashMap` de `get_env`), el valor cacheado se envuelve en un `Arc` (`Arc<HashMap<...>>`). El m√©todo devuelve un `clone()` del `Arc`, que es una operaci√≥n at√≥mica de incremento de contador de referencias (extremadamente r√°pida), en lugar de un `clone()` del `HashMap` completo (extremadamente lento). Esto fue una optimizaci√≥n clave identificada a trav√©s de `flamegraph` para eliminar un cuello de botella severo.

### 4.2. Minimizaci√≥n de Llamadas al Sistema de Archivos

Las operaciones de I/O de disco y las llamadas al sistema son los mayores enemigos de la latencia en un CLI. `axes` las minimiza activamente:

- **Resoluci√≥n de Contexto en Sesi√≥n:** Cuando un usuario est√° dentro de una sesi√≥n (`AXES_PROJECT_UUID` est√° definido), la resoluci√≥n de contextos relativos como `.` se realiza **enteramente en memoria**. En lugar de llamar a `dunce::canonicalize` para preguntar al sistema de archivos cu√°l es el directorio actual, `axes` simplemente usa la ruta del proyecto de la sesi√≥n, que ya est√° cargada en el `GlobalIndex`.
- **Validaci√≥n de Cach√© por Hash:** El sistema de cach√© no depende de marcas de tiempo (`timestamps`) de archivos, que pueden ser inconsistentes. Utiliza un hash criptogr√°fico (`blake3`) del contenido del `axes.toml`. Esto no solo es m√°s robusto, sino que en muchos sistemas operativos modernos, leer un archivo peque√±o para hashearlo puede ser m√°s r√°pido que m√∫ltiples accesos a metadatos si el contenido ya est√° en el cach√© de p√°gina del SO.

### 4.3. Elecci√≥n de Dependencias de Alto Rendimiento

La pila de dependencias de `axes` ha sido seleccionada con el rendimiento como criterio principal:

- **`bincode` vs. `serde_json`/`serde_toml`:** Para la serializaci√≥n de la cach√© y el √≠ndice, `bincode` ofrece un rendimiento de deserializaci√≥n muy superior a los formatos de texto, ya que no requiere un analizador l√©xico/sint√°ctico.
- **`rayon`:** Para la carga concurrente de capas, `rayon` proporciona un pool de hilos "work-stealing" de clase mundial con una sobrecarga m√≠nima, permitiendo una paralelizaci√≥n casi ideal de las tareas de I/O y compilaci√≥n.
- **`clap`:** Se utiliza para el parseo de argumentos del CLI. Su macro `derive` genera c√≥digo de parseo altamente optimizado en tiempo de compilaci√≥n, resultando en un an√°lisis de argumentos muy r√°pido en tiempo de ejecuci√≥n.

### 4.4. Conclusi√≥n: Una Arquitectura Orientada al Rendimiento

Cada decisi√≥n de dise√±o en `axes` ha sido tomada a trav√©s del prisma de la optimizaci√≥n del rendimiento, priorizando la velocidad en la "ruta caliente" (la ejecuci√≥n de comandos por parte del usuario).

- Hemos **movido costes computacionales** del tiempo de ejecuci√≥n al tiempo de compilaci√≥n de la cach√© (`AOT Compilation to AST`).
- Hemos **eliminado la redundancia** de c√°lculos mediante la memorizaci√≥n (`ResolvedConfig`).
- Hemos **minimizado las operaciones lentas** como el I/O y el parsing de texto, reemplaz√°ndolas por lectura binaria y operaciones en memoria.

El resultado es un sistema que no solo se siente r√°pido, sino que est√° emp√≠ricamente demostrado que supera a sus competidores, proporcionando una base s√≥lida y de alto rendimiento sobre la cual construir el futuro de la orquestaci√≥n de flujos de trabajo.
