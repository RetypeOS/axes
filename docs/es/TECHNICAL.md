<p align="center">
  <strong>Read this in other languages:</strong><br>
  <a href="../../TECHNICAL.md">English</a> ‚Ä¢ 
  <a href="./TECHNICAL.md">Espa√±ol</a>
</p>

> **Nota:** Esta traducci√≥n es mantenida por la comunidad y podr√≠a no estar completamente sincronizada con la [versi√≥n en ingl√©s](../../TECNICAL.md), que es la fuente can√≥nica de la documentaci√≥n.

# 1. Introducci√≥n y Filosof√≠a de Dise√±o

Este documento proporciona un an√°lisis t√©cnico en profundidad de la arquitectura interna de `axes`. A diferencia de la documentaci√≥n de usuario, su prop√≥sito es detallar las decisiones de dise√±o, los patrones de software y las estrategias de optimizaci√≥n que permiten a `axes` cumplir sus objetivos de rendimiento y robustez.

## 1.1. El Problema T√©cnico Abordado

Los ejecutores de tareas tradicionales operan sobre un modelo sin estado y basado en texto. Este enfoque, aunque simple, introduce cuellos de botella fundamentales a medida que la complejidad del proyecto escala:

1. **Sobrecarga de Parseo en la Ruta Caliente (Hot Path):** Cada ejecuci√≥n requiere leer y parsear archivos de configuraci√≥n de texto (ej., `Makefile`, `Justfile`, `package.json`), una operaci√≥n intensiva en I/O y CPU que se repite innecesariamente.
2. **Gesti√≥n Impl√≠cita de Dependencias:** La relaci√≥n entre diferentes componentes de un monorepo (ej., `api` depende de `common-lib`) no est√° formalizada, lo que lleva a flujos de trabajo fr√°giles y a la falta de herencia de configuraci√≥n.
3. **Falta de Identidad Persistente:** Identificar un proyecto bas√°ndose en su ruta del sistema de archivos es inherentemente vol√°til. Operaciones como renombrar o mover un directorio rompen flujos de trabajo y referencias.

`axes` fue dise√±ado desde cero para resolver estos problemas a nivel arquitect√≥nico.

### 1.2. Los Tres Pilares de la Arquitectura de `axes`

La arquitectura de `axes` se asienta en tres principios fundamentales que funcionan sin√©rgicamente para ofrecer un rendimiento de √©lite y una robustez estructural.

#### 1.2.1. Estado Centralizado y Persistente (`GlobalIndex`)

El n√∫cleo de `axes` es un **√≠ndice global** (`GlobalIndex`), una base de datos binaria compacta que act√∫a como la **Fuente √önica de Verdad** para todo el ecosistema de proyectos. Este √≠ndice mapea un **UUID inmutable** para cada proyecto a sus metadatos esenciales, como su ruta f√≠sica, nombre y relaci√≥n padre-hijo.

- **Rendimiento de Inicio:** Al usar un formato binario (`bincode`), la deserializaci√≥n del √≠ndice completo en memoria es √≥rdenes de magnitud m√°s r√°pida que el parseo de un equivalente en formato de texto (JSON, TOML). Esto minimiza dr√°sticamente la latencia de arranque en fr√≠o.
- **Robustez Estructural:** Al desacoplar la identidad l√≥gica (UUID) de la ubicaci√≥n f√≠sica (ruta), el sistema se vuelve resistente a los cambios en el sistema de archivos.

#### 1.2.2. Carga Perezosa y Concurrente (El Patr√≥n `Facade`)

`axes` opera bajo el principio de "trabajo m√≠nimo necesario". La lectura y compilaci√≥n de archivos `axes.toml` no ocurre por adelantado. En su lugar, se construye una estructura liviana en memoria, la `ResolvedConfig`, que act√∫a como una **Fachada** (`Facade`).

- **Resoluci√≥n Bajo Demanda:** Los datos de configuraci√≥n (scripts, variables, etc.) solo se cargan del disco y se combinan cuando se invoca un m√©todo como `get_script()` o `get_env()` por primera vez.
- **Concurrencia Optimizada:** El `ConfigLoader` utiliza un pool de hilos (`rayon`) para cargar y compilar las diferentes capas de la jerarqu√≠a de un proyecto de forma concurrente. La sincronizaci√≥n se gestiona eficientemente usando promesas (`Arc<OnceLock<...>>`), asegurando que cada capa se compile solo una vez, incluso bajo demanda concurrente.

#### 1.2.3. Compilaci√≥n Anticipada (AOT) y Cach√© de AST

Este es el pilar m√°s cr√≠tico para el rendimiento en ejecuciones "calientes". `axes` no es un int√©rprete; es un compilador de flujos de trabajo con cach√© persistente.

- **Compilaci√≥n a AST:** En la primera ejecuci√≥n ("ruta fr√≠a"), `axes` parsea los archivos `axes.toml` y compila los scripts y variables en una representaci√≥n intermedia optimizada: un **√Årbol de Sintaxis Abstracta (AST)**, materializado en nuestras structs `Task`.
- **Cach√© Binaria Persistente:** Este AST se guarda en un archivo de cach√© binario (`.bin`).
- **Ejecuciones Instant√°neas ("Ruta Caliente"):** Las ejecuciones posteriores se saltan por completo el costoso parseo de texto. `axes` deserializa el AST pre-compilado desde el cach√© binario‚Äîuna operaci√≥n √≥rdenes de magnitud m√°s r√°pida que el parseo de texto‚Äîy lo ejecuta instant√°neamente.

**El resultado: pagas el costo de la orquestaci√≥n una vez. Obtienes la velocidad de un ejecutor simple cada vez despu√©s.**

- ‚öôÔ∏è **[An√°lisis T√©cnico Completo de la Arquitectura (`TECHNICAL.md`)](./TECNICAL.md):** Para aquellos interesados en la ingenier√≠a detr√°s de nuestro rendimiento.

### 1.3. Diagrama de Flujo: El Ciclo de Vida AOT + JIT

El siguiente diagrama ilustra el ciclo de vida de una ejecuci√≥n de script, destacando la compilaci√≥n AOT (Anticipada) en la "ruta fr√≠a" y la optimizaci√≥n JIT (Justo a Tiempo) en la "ruta caliente".

```mermaid
graph TD
    subgraph "Ciclo de Vida de la Configuraci√≥n en `axes`"
        A["<br><b>Inicio</b><br>Comando axes ejecutado"] --> B{"<br>¬øHay cach√© binaria v√°lida<br>disponible para todas las capas de la jerarqu√≠a?"};

        B -- "<b>‚ùÑÔ∏è No (Ruta Fr√≠a / Fallo de Cach√©)</b>" --> C_IO["<br><b>[COMPILACI√ìN AOT]</b><br>1. Lectura de `axes.toml` (I/O de Disco)"]
        C_IO --> C_CPU["<br>2. Compilar a <b>AST Universal</b> (Intensivo en CPU)"]
        C_CPU --> D_IO["<br>3. Escritura de AST Universal a<br>Cach√© Binaria (I/O de Disco)"]
        D_IO --> E["<br><b>[En Memoria]</b><br>Cargar AST Universal reci√©n compilado"]
        
        B -- "<b>üî• S√≠ (Ruta Caliente / Acierto de Cach√©)</b>" --> H_IO["<br><b>[I/O + CPU M√≠nimos]</b><br>1. Deserializar AST Universal<br>desde Cach√© Binaria"]
        H_IO --> E
        
        E --> I_JIT["<br><b>[OPTIMIZACI√ìN JIT]</b><br>Especializar AST Universal a<br>Tarea Espec√≠fica de Plataforma (En Memoria)"]
        
        I_JIT --> F["<br><b>Ejecuci√≥n</b><br>TaskExecutor opera sobre la<br>lista de tareas simple y especializada en plataforma"]
        F --> G["<br><b>Fin</b><br>"]
    end

    %% Low-cost nodes (in-memory operations, decisions)
    style A fill:#e6f7ff,stroke:#0050b3,stroke-width:1px,color:#055
    style B fill:#e6f7ff,stroke:#0050b3,stroke-width:2px,color:#055
    style E fill:#d6f7ff,stroke:#0050b3,stroke-width:1px,color:#055
    style I_JIT fill:#d6f7ff,stroke:#0050b3,stroke-width:1px,color:#055
    style F fill:#d6f7ff,stroke:#0050b3,stroke-width:2px,color:#055
    style G fill:#d6f7ff,stroke:#595959,stroke-width:1px,color:#055

    %% Hot Path Nodes (Optimized I/O and CPU)
    style H_IO fill:#d9f7be,stroke:#237804,stroke-width:2px,color:#055
    
    %% Cold Path Nodes (High Cost)
    style C_IO fill:#fff1b8,stroke:#d48806,stroke-width:2px,color:#055
    style C_CPU fill:#ffd8bf,stroke:#d46b08,stroke-width:2px,color:#055
    style D_IO fill:#ffdfd7,stroke:#cf1322,stroke-width:2px,color:#055
```

Esta arquitectura **AOT + JIT** proporciona lo mejor de ambos mundos:

- La **Compilaci√≥n AOT** paga el costo de parseo y compilaci√≥n una sola vez, creando una **cach√© universal y portable**.
- La **Especializaci√≥n JIT** realiza una transformaci√≥n final, ultrarr√°pida, en memoria que proporciona al `TaskExecutor` una lista de comandos simple y plana, asegurando que la ruta caliente tenga cero sobrecarga de toma de decisiones.

Esta arquitectura de compilaci√≥n y cach√© es lo que nos permite ofrecer el poder de la orquestaci√≥n compleja a una velocidad que rivaliza con la de los ejecutores m√°s simples. Adem√°s, el uso de hashes para los nombres de los archivos de cach√© permite que esta cach√© sea **compartida entre los miembros del equipo** a trav√©s de una unidad de red o un sistema de cach√© distribuido, asegurando que el costo de compilaci√≥n se pague **solo una vez para todo el equipo**.

## 2. Anatom√≠a de la Ejecuci√≥n de Comandos: El Ciclo de Vida de un Comando

El proceso de ejecuci√≥n de comandos en `axes` est√° rigurosamente coreografiado para maximizar la velocidad, la seguridad y el consumo perezoso de recursos.

### 2.1. El Despachador Universal y la Gram√°tica

El binario de `axes` recibe todos los argumentos en un vector (`Vec<String>`) y utiliza una gram√°tica universal (implementada en `bin/axes.rs`) para determinar la intenci√≥n del usuario. Esta l√≥gica tiene tres reglas de decisi√≥n primarias (Contexto, Acci√≥n, Argumentos) y es el punto donde se decide qu√© porci√≥n de la entrada se interpretar√° como el contexto (`<ctx>`) y cu√°l como comandos para el manejador (`[args...]`).

### 2.2. Resoluci√≥n de Contexto y Persistencia de Identidad (`core/context_resolver.rs`)

Antes de cargar cualquier configuraci√≥n, el sistema debe saber sobre qu√© proyecto est√° operando.

1. **Prioridad de Resoluci√≥n:** El `context_resolver` transforma una entrada de texto (ej., `mi-app/api` o `g!`) en el **UUID** can√≥nico del proyecto. La resoluci√≥n sigue un orden estricto de prioridad: Alias (`g!`, `db!`), Navegaci√≥n Relativa (`.`, `..`, `*`, `**`), y finalmente Nombres de Proyecto (b√∫squeda jer√°rquica).
2. **Referencia Local (`ProjectRef`):** El sistema mantiene un archivo binario de referencia local (`project_ref.bin`) en cada directorio de proyecto (`.axes/`). Este archivo almacena el propio `UUID` del proyecto, el `UUID` de su padre y su nombre simple. Si el √≠ndice global se corrompe, `axes` puede reconstruir la identidad del proyecto a partir de esta referencia local, asegurando la auto-reparaci√≥n del sistema.
3. **Optimizaci√≥n `last_used`:** Cada resoluci√≥n exitosa de contexto actualiza los *punteros de cach√©* (`last_used`, `last_used_child`) en el `GlobalIndex` para acelerar futuras b√∫squedas (`**` y `*`).

### 2.3. Carga de Capas Concurrente (`core/config_loader.rs`)

Una vez que se conoce el `UUID` del proyecto objetivo, la fachada `ResolvedConfig` inicia la fase de carga.

El `ConfigLoader` determina la cadena de herencia completa (desde el `UUID` objetivo hasta el proyecto ra√≠z `global`) y orquesta la carga de las capas de configuraci√≥n de estas cadenas de forma concurrente para minimizar la latencia.

#### Diagrama: Flujo de Carga de Capas

```mermaid
graph TD
    A["ResolvedConfig.get_env()"] --> B("ConfigLoader");
    B --> C("Identificar Jerarqu√≠a: [UUID_A, UUID_P, UUID_G]");

    C --> D_R(Rayon::scope);
    
    D_R --> E1("Tarea 1: load_layer_task(UUID_A)");
    D_R --> E2("Tarea 2: load_layer_task(UUID_P)");
    D_R --> E3("Tarea 3: load_layer_task(UUID_G)");

    E1 --> F1{"¬øAcierto/Fallo de Cach√©?"};
    E2 --> F2{"¬øAcierto/Fallo de Cach√©?"};
    E3 --> F3{"¬øAcierto/Fallo de Cach√©?"};

    F1 --> G_A("LayerPromise.set(Resultado<Arc<Task>>)");
    F2 --> G_P("LayerPromise.set(Resultado<Arc<Task>>)");
    F3 --> G_G("LayerPromise.set(Resultado<Arc<Task>>)");

    G_A --> H("ResolvedConfig.get_layer(UUID_A)");
    G_P --> H;
    G_G --> H;

    H --> I["Fusi√≥n de Datos y Memoizaci√≥n"];
    I --> J["Resultado Final"];

    style D_R fill:#d9f7be,stroke:#237804,stroke-width:2px,color:#055
    style E1 fill:#fff1b8,stroke:#d48806,stroke-width:1px,color:#055
    style E2 fill:#fff1b8,stroke:#d48806,stroke-width:1px,color:#055
    style E3 fill:#fff1b8,stroke:#d48806,stroke-width:1px,color:#055

    %% Efficient synchronization using Arc/OnceLock
    H -.-> G_A; 
    H -.-> G_P; 
    H -.-> G_G;
```

#### Mecanismos de Sincronizaci√≥n

1. **`LayerPromise` (`Arc<OnceLock<...>>`):** Cada tarea de carga de capa es as√≠ncrona. El `ResolvedConfig` obtiene una "promesa" para el resultado. El uso de `OnceLock` es crucial: si un hilo ya est√° calculando la cach√© para una capa, cualquier otro hilo que la necesite simplemente **se bloquea y espera** en el mismo `OnceLock`. Esto asegura que la costosa operaci√≥n de `Fallo de Cach√©` (I/O + Compilaci√≥n) nunca se duplique, incluso en entornos altamente concurrentes.
2. **Manejo de `Fallo de Cach√©`:** Si se detecta un `Fallo de Cach√©` (el `axes.toml` ha cambiado), la tarea de carga procede a la compilaci√≥n y produce un `IndexUpdate`. Estas *actualizaciones* son recolectadas por el hilo principal y aplicadas al `GlobalIndex` en un orden secuencial (antes de que la aplicaci√≥n termine), garantizando la seguridad de la cach√©.

### 2.4. El Modelo de Comando: Compilaci√≥n a AST

La compilaci√≥n es el paso donde el texto del usuario se transforma en una estructura de datos optimizada y ejecutable.

1. **De TOML a AST:** `axes` convierte el `ProjectConfig` flexible (el formato de texto) en un `CachedProjectConfig`. Este proceso implica transformar cada `Command` en una `Task`, que es nuestra representaci√≥n materializada y optimizada del AST. Una `Task` contiene una secuencia de `CommandExecution`.
2. **Prop√≥sito de `Task`:** Almacenar scripts pre-parseados y tokens resueltos (`TemplateComponent`), junto con metadatos de ejecuci√≥n (`ignore_errors`, `run_in_parallel`). Esto elimina la necesidad de `shlex` y el parseo de plantillas en tiempo de ejecuci√≥n.
3. **Separaci√≥n de Modelos:** La cach√© binaria (`bincode`) solo almacena la `Task` compilada (y no el tipo intermedio `Command`), asegurando que la serializaci√≥n binaria sea segura, r√°pida e inequ√≠voca.

### 3. Las Estructuras de Datos Fundamentales y su Dise√±o

El rendimiento y la robustez de `axes` no son solo el resultado de los algoritmos, sino tambi√©n del dise√±o deliberado de sus estructuras de datos. Cada `struct` ha sido dise√±ada para un prop√≥sito espec√≠fico dentro del ciclo de vida de la aplicaci√≥n.

### 3.1. Dualidad de Estado: `GlobalIndex` vs. `ProjectRef`

`axes` gestiona el estado en dos niveles: uno global y uno local, creando un sistema resiliente y auto-reparador.

- **`GlobalIndex` (El Mapa Global):**
  - **Estructura:** Un √∫nico archivo binario (`index.bin`) que contiene principalmente un `HashMap<Uuid, IndexEntry>`.
  - **Prop√≥sito:** Act√∫a como el √≠ndice primario para todas las operaciones de b√∫squeda y resoluci√≥n de contexto. Permite la resoluci√≥n de UUID a metadatos (ruta, nombre, padre) en tiempo constante O(1).
  - **Optimizaci√≥n de Alias:** Mantiene un `HashMap<String, Uuid>` separado para los alias. Esta es una decisi√≥n de dise√±o cr√≠tica: desacopla los "atajos" de la estructura jer√°rquica principal. Permite relaciones de alias de muchos a uno (m√∫ltiples alias pueden apuntar al mismo proyecto), una flexibilidad que se perder√≠a si el alias fuera una propiedad del `IndexEntry`.

- **`ProjectRef` (La Identidad Local):**
  - **Estructura:** Un peque√±o archivo binario (`.axes/project_ref.bin`) dentro de cada directorio de proyecto.
  - **Prop√≥sito:** Act√∫a como una "etiqueta de identidad" inmutable para el proyecto. Almacena su propio `self_uuid`, `name` y `parent_uuid`.
  - **Robustez y Auto-Reparaci√≥n:** Este archivo es la clave de la resiliencia de `axes`. Si el `GlobalIndex` se corrompe o se elimina, el comando `axes register` puede recorrer el sistema de archivos y utilizar los archivos `project_ref.bin` para **reconstruir el √≠ndice global** con total fidelidad. Permite que un proyecto sea movido o renombrado en el sistema de archivos y luego "re-registrado" sin perder su identidad hist√≥rica o sus relaciones.

### 3.2. La Cadena de Transformaci√≥n de Comandos: De la Sintaxis de Usuario al AST Optimizado

Para lograr tanto una sintaxis amigable para el usuario como un rendimiento de ejecuci√≥n extremo, `axes` utiliza una cadena de transformaci√≥n de modelos de datos de m√∫ltiples etapas. Esta es la clave de nuestra robustez arquitect√≥nica.

```mermaid
graph LR
    A("<b>1. Sintaxis de Usuario</b><br><code>axes.toml</code>") --> B{"<b>2. Deserializador TOML</b><br>(<code>serde_toml</code>)"};
    
    subgraph "Fase de Compilaci√≥n AOT (Fallo de Cach√©)"
        B --> C["<b>3. Modelos de Sintaxis Flexible</b><br><code>TomlScript</code>, <code>TomlVar</code><br>Usa <code>#[serde(untagged)]</code><br>para aceptar m√∫ltiples formatos."];
        C --> D["<b>4. Compilador (`compiler.rs`)</b><br>Transforma la sintaxis flexible en<br>el AST universal y agn√≥stico a la plataforma."];
        D --> E["<b>5. Modelo AST Universal</b><br><code>Task</code>, <code>CachedVar</code><br>Contiene bloques <code>PlatformExecution</code>.<br>100% compatible con <code>bincode</code>."];
    end
    
    E --> F{"<b>6. Serializador Binario</b><br>(<code>bincode</code>)"};
    F --> G("<b>7. Cach√© de Disco</b><br><code>.bin</code>");

    subgraph "Fase de Ejecuci√≥n (Ruta Caliente)"
        G --> H{"<b>8. Deserializador Binario</b><br>(<code>bincode</code>)"};
        H --> I["<b>9. AST Universal en Memoria</b><br>Cargado directamente, evitando el parseo de texto."];
        I --> J["<b>10. Especializador JIT</b><br><code>specialize_task_for_platform()</code><br>Selecciona comandos para el SO actual."];
        J --> K["<b>11. AST Especializado en Plataforma</b><br><code>PlatformSpecializedTask</code><br>Una lista de comandos simple y plana."];
    end
    
    K --> L("<b>12. <code>TaskExecutor</code></b><br>Opera sobre el AST plano<br>con cero sobrecarga.");

    %% Styles
    style A fill:#f0f0f0,stroke:#333,color:#055
    style G fill:#f0f0f0,stroke:#333,color:#055
    style C fill:#e6f7ff,stroke:#096dd9,color:#055
    style D fill:#bae7ff,stroke:#096dd9,color:#055
    style E fill:#d9f7be,stroke:#237804,color:#055
    style I fill:#d9f7be,stroke:#237804,color:#055
    style J fill:#d9f7be,stroke:#237804,color:#055
    style K fill:#d9f7be,stroke:#237804,color:#055
```

- **`TomlScript`, `TomlVar`:** Estas structs de "solo lectura" est√°n dise√±adas con la m√°xima flexibilidad para el usuario, utilizando atributos como `#[serde(untagged)]` y `#[serde(deny_unknown_fields)]` para proporcionar una experiencia de configuraci√≥n ergon√≥mica y resistente a errores.
- **`Task`, `CachedVar` (El AST Universal):** Este es el producto final de la compilaci√≥n AOT. Es una representaci√≥n optimizada en memoria para el almacenamiento, que contiene bloques `PlatformExecution` que albergan la l√≥gica para todos los sistemas operativos. Esta estructura es la que se serializa con `bincode` en la cach√©.
- **`PlatformSpecializedTask` (El AST Optimizado por JIT):** Esta es una estructura transitoria, solo en memoria, creada justo antes de la ejecuci√≥n. Representa la ruta de ejecuci√≥n m√°s r√°pida posible, ya que todas las decisiones espec√≠ficas de la plataforma ya se han tomado.

### 3.3. El Resolvedor de Argumentos (`ArgResolver`): Manejo de Par√°metros de Cero Copia

El `ArgResolver` es un componente de alto rendimiento que valida y resuelve todos los par√°metros del script *antes* de que comience la ejecuci√≥n.

- **Validaci√≥n de Contrato Pre-Ejecuci√≥n:** El sistema primero recopila todas las definiciones de par√°metros (`<params::...>`) de todo el script (potencialmente compuesto). Esto forma un "contrato" completo. Luego, el `ArgResolver` se construye una vez, validando los argumentos CLI del usuario contra este contrato. Esto atrapa todos los errores‚Äîpar√°metros requeridos faltantes, conflictos de banderas‚Äîpor adelantado.
- **Rendimiento de Cero Copia:** El `ArgResolver` est√° dise√±ado para ser extremadamente eficiente en memoria. Utiliza el sistema de *lifetimes* de Rust para **tomar prestados** los argumentos de la l√≠nea de comandos directamente del `Vec<String>` de entrada en lugar de clonarlos. Esto significa que para un comando como `axes run -- --argumento-largo-1 --argumento-largo-2`, no se realizan nuevas asignaciones de cadenas para los par√°metros, minimizando la sobrecarga de memoria.
- **Resultado Inmutable:** El `ArgResolver` produce un `HashMap` inmutable de valores resueltos. El `TaskExecutor` luego realiza b√∫squedas r√°pidas en este mapa, eliminando cualquier sobrecarga de parseo o validaci√≥n durante el bucle de ejecuci√≥n caliente.

- **Pre-Parseo y Validaci√≥n:** Antes de la ejecuci√≥n, el sistema (`run::handle`, `start::handle`, etc.) atraviesa la `Task` aplanada y recopila **todas** las definiciones de par√°metros (`ParameterDef`) en una sola lista. Esta lista representa el "contrato" completo del script.
- **Resoluci√≥n de una Sola Pasada:** El `ArgResolver` se construye una vez con este contrato y los argumentos del usuario. En su constructor, realiza toda la validaci√≥n:
  - Comprueba que todos los par√°metros `required` est√©n presentes.
  - Detecta conflictos, como el uso simult√°neo de una bandera y su alias (`--verbose` y `-v`).
  - Detecta argumentos inesperados si el script no utiliza el token gen√©rico `<params>`.
- **Resultado Inmutable:** El `ArgResolver` produce un `HashMap` inmutable que mapea el token original (ej., `<params::0(required)>`) a su valor final resuelto. Durante la ejecuci√≥n, el `TaskExecutor` simplemente realiza b√∫squedas r√°pidas en este mapa, sin necesidad de m√°s parseo o validaci√≥n.

### 3.4. El Sistema de Cach√©

- **Cach√© por Capas:** `axes` no tiene una √∫nica cach√© monol√≠tica, sino una cach√© para cada `axes.toml` en la jerarqu√≠a del proyecto. Esto mejora la granularidad y reduce la invalidaci√≥n: un cambio en `mi-app/api/axes.toml` solo invalida la cach√© de `api`, no la de `mi-app` o `global`.
- **Gesti√≥n de Cach√©:** El comando `axes <ctx> _cache clear` invalida la cach√© de una capa espec√≠fica eliminando su `config_hash` y `cache_dir` del `GlobalIndex`. La pr√≥xima vez que se necesite esa capa, se fuerza una recompilaci√≥n. Un futuro comando `axes cache gc` ser√° responsable de limpiar los archivos de cach√© binaria del disco que ya no son referenciados por ning√∫n proyecto en el `GlobalIndex`.

## 4. Optimizaciones Adicionales y Conclusiones de Rendimiento

M√°s all√° de los tres pilares arquitect√≥nicos, `axes` implementa una serie de optimizaciones micro-arquitect√≥nicas para minimizar la latencia en cada operaci√≥n.

### 4.1. Patr√≥n de Memoizaci√≥n en `ResolvedConfig`

La fachada `ResolvedConfig` no solo es perezosa a nivel de I/O de disco, sino tambi√©n a nivel de computaci√≥n. Las operaciones como fusionar variables de entorno a trav√©s de toda una jerarqu√≠a (`get_env()`) son costosas. Para evitar repetir este trabajo, `ResolvedConfig` utiliza un patr√≥n de **memoizaci√≥n** interno.

- **Mecanismo:** Cada m√©todo costoso (ej., `get_env`, `get_options`) utiliza un campo `memoized_*` protegido por un `Mutex`.
  - En la **primera llamada**, el `Mutex` se bloquea, se realiza el c√°lculo costoso (fusionar `HashMap`s de todas las capas) y el resultado se almacena en el campo `memoized_*`.
  - En **llamadas subsiguientes**, el `Mutex` solo se bloquea brevemente para verificar si el resultado ya existe, y lo devuelve instant√°neamente.
- **Optimizaci√≥n con `Arc`:** Para resultados que son colecciones grandes (como el `HashMap` de `get_env`), el valor cacheado se envuelve en un `Arc` (`Arc<HashMap<...>>`). El m√©todo devuelve un `clone()` del `Arc`, que es un incremento at√≥mico del conteo de referencias (extremadamente r√°pido), en lugar de un clon completo de `HashMap` (extremadamente lento). Esta fue una optimizaci√≥n clave identificada a trav√©s de `flamegraph` para eliminar un cuello de botella grave.

### 4.2. Minimizaci√≥n de Llamadas al Sistema de Archivos

Las operaciones de I/O de disco y las llamadas al sistema son los mayores enemigos de la latencia en una herramienta CLI. `axes` las minimiza activamente:

- **Resoluci√≥n de Contexto en Sesi√≥n:** Cuando un usuario est√° dentro de una sesi√≥n (`AXES_PROJECT_UUID` est√° definido), la resoluci√≥n de contexto para referencias como `.` se realiza **completamente en memoria**. En lugar de llamar a `dunce::canonicalize` para preguntar al sistema de archivos por el directorio actual, `axes` simplemente utiliza la ruta del proyecto de la sesi√≥n, que ya est√° cargada en el `GlobalIndex`.
- **Validaci√≥n de Cach√© por Hash:** El sistema de cach√© no se basa en las `timestamps` de los archivos, que pueden ser inconsistentes. Utiliza un hash criptogr√°fico (`blake3`) del contenido de `axes.toml`. Esto no solo es m√°s robusto, sino que en muchos sistemas operativos modernos, leer un archivo peque√±o para hashearlo puede ser m√°s r√°pido que m√∫ltiples accesos a metadatos si el contenido ya est√° en la cach√© de p√°ginas del SO.

### 4.3. Elecci√≥n de Dependencias de Alto Rendimiento

El stack de dependencias de `axes` ha sido seleccionado con el rendimiento como criterio principal:

- **`bincode` vs. `serde_json`/`serde_toml`:** Para la serializaci√≥n de cach√© e √≠ndice, `bincode` ofrece un rendimiento de deserializaci√≥n muy superior en comparaci√≥n con los formatos de texto, ya que no requiere un analizador l√©xico/sint√°ctico.
- **`rayon`:** Para la carga concurrente de capas, `rayon` proporciona un pool de hilos de "robo de trabajo" de clase mundial con una sobrecarga m√≠nima, permitiendo una paralelizaci√≥n casi ideal de las tareas de I/O y compilaci√≥n.
- **`clap`:** Utilizado para el parseo de argumentos CLI. Su macro `derive` genera c√≥digo de parseo altamente optimizado en tiempo de compilaci√≥n, lo que resulta en un an√°lisis de argumentos muy r√°pido en tiempo de ejecuci√≥n.

### 4.4. Conclusi√≥n: Una Arquitectura Orientada al Rendimiento

Cada decisi√≥n de dise√±o en `axes` se ha tomado a trav√©s de la lente de la optimizaci√≥n del rendimiento, priorizando la velocidad en la "ruta caliente" (la ejecuci√≥n de comandos por el usuario).

- Hemos **desplazado los costos computacionales** del tiempo de ejecuci√≥n al tiempo de compilaci√≥n de cach√© (`Compilaci√≥n AOT a AST`).
- Hemos **eliminado la redundancia** a trav√©s de la memoizaci√≥n (`ResolvedConfig`).
- Hemos **minimizado las operaciones lentas** como I/O y parseo de texto, reemplaz√°ndolas con lectura binaria y operaciones en memoria.

El resultado es un sistema que no solo *se siente* r√°pido, sino que emp√≠ricamente demuestra superar a sus competidores, proporcionando una base s√≥lida y de alto rendimiento sobre la cual construir el futuro de la orquestaci√≥n de flujos de trabajo.
